{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook has been made in colab research. To run import into colab and convert bash cells (in markdown) to code cells to download and manage dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "!pip install -q kaggle\n",
    "\n",
    "!mkdir ~/.kaggle\n",
    "!cp -f /root/kaggle.json ~/.kaggle/\n",
    "!chmod 600 /root/.kaggle/kaggle.json\n",
    "\n",
    "!kaggle datasets download -d nadyana/flowers\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zip_ref = zipfile.ZipFile('/content/flowers.zip', 'r')\n",
    "zip_ref.extractall('/content')\n",
    "zip_ref.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "!rm -rf flowers/lotus; rm -rf flowers/bellflower\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import imghdr\n",
    "import os\n",
    "\n",
    "data_dir = \"flowers/\"\n",
    "image_extensions = [\".png\", \".jpg\"]  # add there all your images file extensions\n",
    "\n",
    "img_type_accepted_by_tf = [\"bmp\", \"gif\", \"jpeg\", \"png\"]\n",
    "for filepath in Path(data_dir).rglob(\"*\"):\n",
    "    if filepath.suffix.lower() in image_extensions:\n",
    "        img_type = imghdr.what(filepath)\n",
    "        if img_type is None:\n",
    "            print(f\"{filepath} is not an image\")\n",
    "            os.remove(filepath)\n",
    "        elif img_type not in img_type_accepted_by_tf:\n",
    "            print(f\"{filepath} is a {img_type}, not accepted by TensorFlow\")\n",
    "            os.remove(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = (128,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, BatchNormalization, Dropout, Activation\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds = keras.utils.image_dataset_from_directory(\n",
    "    directory   = '/content/flowers',\n",
    "    validation_split = 0.15,\n",
    "    seed        = 1111,\n",
    "    subset      = \"both\",\n",
    "    labels      ='inferred',\n",
    "    label_mode  = 'int',\n",
    "    batch_size  = BATCH_SIZE,\n",
    "    image_size  = IMAGE_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(int(labels[i]))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(image,label):\n",
    "    image = tf.cast(image/255. ,tf.float32)\n",
    "    return image,label\n",
    "\n",
    "train_ds = train_ds.map(process)\n",
    "val_ds = val_ds.map(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same',activation ='relu', input_shape = (128,128,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    " \n",
    "model.add(Conv2D(filters =96, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters = 96, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dense(5, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD,Adam\n",
    "learn_rate=.001\n",
    "\n",
    "# https://stackoverflow.com/questions/49922252/choosing-number-of-steps-per-epoch\n",
    "batch_size=150\n",
    "epochs=4\n",
    "\n",
    "# https://keras.io/api/optimizers/sgd/\n",
    "sgd = SGD(learning_rate=learn_rate, momentum=.9, nesterov=True)\n",
    "model.compile(optimizer=sgd,loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "#model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#from keras.callbacks import ReduceLROnPlateau\n",
    "#red_lr= ReduceLROnPlateau(monitor='val_acc',patience=3,verbose=1,factor=0.1)\n",
    "#model.compile(optimizer=Adam(lr=0.001),loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EvMod = model.fit(train_ds, epochs=10, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./test-v3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.saving.load_model(\"./test-v3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "image_size = (128, 128)\n",
    "\n",
    "imagem = cv2.imread('/content/campo-com-girassol-683x1024.jpg')\n",
    "#imagem = cv2.imread('/content/girassol_04jul22_Mahathir-Mohd-Yasin_EyeEm_Gettyimages-768x512.jpg')\n",
    "imagem = cv2.resize(imagem, image_size)\n",
    "imagem = imagem.reshape((1,128,128,3))\n",
    "imagem = tf.cast(imagem/255. ,tf.float32)\n",
    "\n",
    "model.predict(imagem).round()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
